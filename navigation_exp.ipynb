{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9c3345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import open3d as o3d\n",
    "import time\n",
    "import numpy as np\n",
    "from vggt.models.vggt import VGGT\n",
    "from modules.aligned_vggt_main_lidar import AlignedVGGTLidar\n",
    "from modules.utils import *\n",
    "from modules.input_stream_main import *\n",
    "from modules.visualizer import *\n",
    "from modules.semantic_segmentator import *\n",
    "from modules.instance_tracker import *\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "from modules.floor_plane_clean import FloorPlaneFinder\n",
    "from modules.navigation_new import NavMapGenerator\n",
    "from modules.anna import Anna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d42534d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "model = VGGT.from_pretrained(\"facebook/VGGT-1B\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff00988",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"path/to/folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de2b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_imgs_to_use, step = 1500, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc6b320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb folder is not none, it is:  /media/buvar/HBVCSSD/__DATA__/in-the-wild-PPCU/noFilter_lab240_20260130/2026_01_30_taskname_H0x0yW_frames/\n"
     ]
    }
   ],
   "source": [
    "input_stream = InputStreamMain(rgb_folder=base_path,rgb_pattern=\"colorImg*.jpg\",depth_folder=base_path,depth_pattern=\"depthMat*.csv\",data_limit=num_of_imgs_to_use,step=step)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a072e79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_img_size = input_stream.img_size\n",
    "w, h = input_stream.img_size\n",
    "fixed_w = 518\n",
    "vggt_img_size = (fixed_w, int(round(h * (fixed_w / w) / 14) * 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e86e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis_options = vis.get_render_option()\n",
    "ctr = vis.get_view_control()\n",
    "ctr.rotate(90.0, 90.0, 0.0)\n",
    "ctr.translate(-10.0, 0.0)\n",
    "vis_options.background_color = np.asarray([0,0,0])\n",
    "vis_options.point_size = 2.0\n",
    "# Initiate interactive viewer\n",
    "vis.clear_geometries()\n",
    "vis.poll_events()\n",
    "vis.update_renderer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5466260",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = YOLO(\"yolov9e-seg.pt\")\n",
    "type_list = list(range(80))\n",
    "yolo_model.overrides[\"classes\"] = type_list\n",
    "type_name_dict = { 0: \"person\",  1: \"bicycle\",  2: \"car\",  3: \"motorcycle\",  4: \"airplane\",  5: \"bus\",  6: \"train\",  7: \"truck\",  8: \"boat\",  9: \"traffic light\",  10: \"fire hydrant\",  11: \"stop sign\",  12: \"parking meter\",  13: \"bench\",  14: \"bird\",  15: \"cat\",  16: \"dog\",  17: \"horse\",  18: \"sheep\",  19: \"cow\",  20: \"elephant\",  21: \"bear\",  22: \"zebra\",  23: \"giraffe\",  24: \"backpack\",  25: \"umbrella\",  26: \"handbag\",  27: \"tie\",  28: \"suitcase\",  29: \"frisbee\",  30: \"skis\",  31: \"snowboard\",  32: \"sports ball\",  33: \"kite\",  34: \"baseball bat\",  35: \"baseball glove\",  36: \"skateboard\",  37: \"surfboard\",  38: \"tennis racket\",  39: \"bottle\",  40: \"wine glass\",  41: \"cup\",  42: \"fork\",  43: \"knife\",  44: \"spoon\",  45: \"bowl\", 46: \"banana\",  47: \"apple\",  48: \"sandwich\",  49: \"orange\",  50: \"broccoli\",  51: \"carrot\",  52: \"hot dog\",  53: \"pizza\",  54: \"donut\",  55: \"cake\",  56: \"chair\",  57: \"couch\",  58: \"potted plant\",  59: \"bed\",  60: \"dining table\",  61: \"toilet\",  62: \"tv\",  63: \"laptop\",  64: \"mouse\",  65: \"remote\",  66: \"keyboard\",  67: \"cell phone\",  68: \"microwave\",  69: \"oven\",  70: \"toaster\",  71: \"sink\",  72: \"refrigerator\",  73: \"book\",  74: \"clock\",  75: \"vase\",  76: \"scissors\",  77: \"teddy bear\",  78: \"hair drier\",  79: \"toothbrush\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b9c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_segmentator = SemanticSegmentator(yolo_model,type_name_dict,type_list,vggt_img_size,conf_threshold=0.4)\n",
    "instance_tracker = InstanceTracker(vggt_img_size,type_list)\n",
    "renderer = Renderer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a601ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane = FloorPlaneFinder()\n",
    "#change min_height if the floor points are in the nav map\n",
    "navmap = NavMapGenerator(0.05,min_height=0.2,max_height=2.0,normal_min_height=0.4,normal_threshold=0.8)\n",
    "plane.it_n = 1000\n",
    "plane.exp_vector_confusion = False\n",
    "#plane.d_tr = 0.075\n",
    "plane.exp_d_adjust = True\n",
    "plane_updates = []\n",
    "meanmap_tr = 1\n",
    "plane_ds_rate = 10\n",
    "navmap_input_pcd = np.empty((0,3))\n",
    "\n",
    "def generate_plane_mesh(size,height,color):\n",
    "    vert = np.array([\n",
    "        [size,size,0],[-size,size,0],[size,-size,0],[-size,-size,0]\n",
    "    ])\n",
    "    tri = np.array([\n",
    "        [0,2,3],[0,3,1]\n",
    "    ])\n",
    "    tnorm = np.array([\n",
    "        [0,0,-1],[0,0,-1]\n",
    "    ])\n",
    "    vnorm = np.array([\n",
    "        [0,0,-1],[0,0,-1],[0,0,-1],[0,0,-1]\n",
    "    ])\n",
    "    plane = o3d.geometry.TriangleMesh.create_box(2*size,2*size,height)\n",
    "    plane.translate([-size,-size,0])\n",
    "    plane.paint_uniform_color(color)\n",
    "    return plane\n",
    "plane_mesh = generate_plane_mesh(10,1/1000,[0,0.5,0.5])\n",
    "\n",
    "plane_mesh_rotated = generate_plane_mesh(10,1/1000,[0,0.5,0.5])\n",
    "\n",
    "def simple_aggregate(per_frame_pcd,ds_rate): # TODO Switch to filtered visualizer fn.\n",
    "    full_pcd = np.empty((0,3))\n",
    "    for pcd in per_frame_pcd:\n",
    "        full_pcd = np.append(full_pcd,np.reshape(pcd,(-1,3))[::ds_rate],0)\n",
    "    return full_pcd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aa363d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_map(name,map,cmin=0.0,cmax=2.0):\n",
    "    r = np.logical_not(np.isnan(map))\n",
    "    g = np.zeros_like(map)\n",
    "    if np.any(r):\n",
    "        g[r] = np.clip(map[r]-cmin,cmin,cmax)/(cmax-cmin)*255\n",
    "\n",
    "    b = np.zeros_like(map)\n",
    "    r = r*255\n",
    "    bgr = np.dstack((b,g,r)).astype(np.uint8)\n",
    "    cv2.imshow(name,np.flip(bgr,0))\n",
    "\n",
    "def vis_semantic_map(name,map,block_id):\n",
    "    cmap = Renderer.get_color_map()\n",
    "    bgr = np.empty((map.shape[0],map.shape[1],3),dtype=np.uint8)\n",
    "    for x in range(0,bgr.shape[0]):\n",
    "        for y in range(0,bgr.shape[1]):\n",
    "            id = map[x,y]\n",
    "            if np.isnan(id):\n",
    "                bgr[x,y,:] = [0,0,0]\n",
    "            else:\n",
    "                bgr[x,y,:] = cmap[int(id)]\n",
    "\n",
    "    cv2.imshow(name,np.flip(bgr,0))\n",
    "    cv2.imwrite(f\"output/navmap-lab-nd/{block_id}.png\",np.flip(bgr,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b617bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "aligned_vggt = AlignedVGGTLidar(model,block_size = 10,keyframe_per_block = 10,keyframe_memory_cap = 10, depth_conf_threshold = 1.1,device = device)\n",
    "last_full_block = list(range(0,len(input_stream),aligned_vggt.block_size))[-1] # To handle if the frame num is not divisible by the block size\n",
    "use_semantics = True\n",
    "use_instance_tracking = True\n",
    "do_navigation = True\n",
    "rotated_fully_aggregated_pcd = o3d.geometry.PointCloud()\n",
    "pathfinder = Anna(vggt=aligned_vggt)\n",
    "if len(input_stream) % aligned_vggt.block_size != 0:\n",
    "    last_full_block -= aligned_vggt.block_size\n",
    "for block_idx in tqdm(range(0,last_full_block+1,aligned_vggt.block_size)):\n",
    "    aggregated_pcd = o3d.geometry.PointCloud()\n",
    "    start_time = time.time()\n",
    "    # Get frames relevant to this block\n",
    "    frames = input_stream.get_frames(aligned_vggt.block_size)\n",
    "    if use_instance_tracking == True:\n",
    "        tracked_frames = aligned_vggt.keyframe_list + frames\n",
    "        block_indices = list(range(block_idx,int(np.amin([block_idx+aligned_vggt.block_size,len(input_stream)]))))\n",
    "        tracked_frame_indices = aligned_vggt.keyframe_list_idx + block_indices\n",
    "    if frames[0] is None:\n",
    "        break\n",
    "    # Process new frames and keyframes with VGGT\n",
    "    print(f\"Block {block_idx}\")\n",
    "    images, per_frame_point_clouds, depth_mask = aligned_vggt.process_frames(frames, block_idx)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    if use_semantics == True:\n",
    "        start_time = time.time()\n",
    "        semantic_segmentator.segment_frames(frames,aligned_vggt,block_idx)\n",
    "        end_time = time.time()\n",
    "    if use_instance_tracking == True:\n",
    "        start_time = time.time()\n",
    "        instance_tracker.run_instance_tracking(aligned_vggt,semantic_segmentator,tracked_frame_indices)\n",
    "        end_time = time.time()\n",
    "    if use_semantics == True and do_navigation == True:\n",
    "        \n",
    "        transform_updated = plane.advance(aligned_vggt,semantic_segmentator)\n",
    "        last_block_pcd = renderer.create_semantic_pcd(aligned_vggt,semantic_segmentator,False,True,downsample_rate=10)\n",
    "        navmap_input_pcd = np.append(navmap_input_pcd,np.asarray(last_block_pcd.points),0)\n",
    "\n",
    "        if transform_updated is not plane.STATE_NO_UPDATE:\n",
    "            plane_updates.append((block_idx,transform_updated))\n",
    "\n",
    "        if transform_updated != plane.STATE_NO_UPDATE:\n",
    "            navmap.reset(plane.transform,navmap_input_pcd,semantic_segmentator)\n",
    "        else:\n",
    "            navmap.update(plane.transform,np.asarray(last_block_pcd.points),semantic_segmentator)\n",
    "        \n",
    "        pathfinder.get_navigation_and_visualize(\n",
    "            block_idx=block_idx,\n",
    "            navmap=navmap,\n",
    "            plane=plane,\n",
    "            goal_id=1\n",
    "        )\n",
    "\n",
    "        vis_map(\"mean\",navmap.get_mean(),0,5)\n",
    "        vis_map(\"min\",navmap.min)\n",
    "        vis_map(\"max\",navmap.max)\n",
    "        vis_semantic_map(\"semantics\",navmap.semantic,block_idx)\n",
    "        cv2.waitKey(1)\n",
    "    \n",
    "    aligned_vggt.clean_memory()\n",
    "    start_time = time.time()\n",
    "    if use_semantics == True:\n",
    "        if do_navigation == True:\n",
    "            rendered_pcd = last_block_pcd\n",
    "        else:\n",
    "            rendered_pcd = renderer.create_semantic_pcd(aligned_vggt,semantic_segmentator,False,True,downsample_rate=10)\n",
    "    else:\n",
    "        rendered_pcd = renderer.create_aggregated_pcd(aligned_vggt,True,downsample_rate=10)\n",
    "    R = rendered_pcd .get_rotation_matrix_from_axis_angle([np.radians(220), 0, 0])\n",
    "    rendered_pcd .rotate(R, center=(0, 0, 0)) \n",
    "    if use_semantics == True and do_navigation == True and transform_updated is not plane.STATE_NO_UPDATE:\n",
    "        vis.remove_geometry(plane_mesh_rotated)\n",
    "        plane_mesh_rotated = copy.deepcopy(plane_mesh).transform(plane.inv_transform)\n",
    "        R = plane_mesh_rotated.get_rotation_matrix_from_axis_angle([np.radians(220), 0, 0])\n",
    "        plane_mesh_rotated.rotate(R, center=(0, 0, 0)) \n",
    "        vis.add_geometry(plane_mesh_rotated)\n",
    "\n",
    "    if len(rendered_pcd.points) > 0:\n",
    "        vis.add_geometry(rendered_pcd)\n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "    end_time = time.time()\n",
    "    print(f\"Rendered {len(aligned_vggt.keyframe_list_idx) + len(frames)} frames in {end_time - start_time}s\")\n",
    "vis.run()\n",
    "vis.destroy_window()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vggt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
